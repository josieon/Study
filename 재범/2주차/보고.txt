현재 진행상황 부터 말씀드리겠습니다!
1. 7개의 단어에서 12개의 단어에 대한 분류를 진행하였습니다.
- 수어 동작이 비슷한, 예를 들어 "주세요", "친구" 두 단어는 손바닥이
서로 마주보며 박수치는 동작인데 이럴 경우 원하는 결과를 얻지 못하고 
분류가 잘 되지 않았습니다.

2. 분류된 단어를 바탕으로 5개의 단어를 선정하여 문장을 생성하는 
모델을 직접 만들었습니다. 
- 예를 들어 '나', '친구', '먼저', '도착', '있다' 5개의 단어를 모델의 input으로 
넣으면 "제 친구 먼저 도착해 있습니다" 라는 문장을 생성하도록 만들었습니다.
- 예전에 교수님께서 추천해주신 방법인 konlpy를 사용했을 때 
모델이 여러 품사들을 제대로 구별을 하는데에 있어서 한계가 있어서 
사용을 하지 않았습니다.

현재 가장 큰 문제점은 위에서 첫 번째로 말한바와 같이 
몇몇의 단어에 대한 분류가 제대로 이뤄지지 않고 있습니다. 
이에 대하여 저희가 진행하고 있는 해결방법입니다.

1. 사용자와 카메라의 거리를 cv2와 mediapipe를 이용해서 측정하여
일정거리에서만 사용자가 수어 번역기를 사용할수 있게하는 것입니다
-> 이는 파이썬의 with open 문을 두 가지를 한꺼번에 사용해야 하지만,
실행에 오류가 있었는데 오류 해결 방법을 아직까지 못 찾아서 보류 중입니다.

2. 키포인트를 생각해본 결과 손을 제외한 신체 부위를 나타내는 키포인트가
불필요하다 생각하여 전부 제거 하였습니다. 
그 후 데이터의 양을 여러사람을 이용해서 증가 시켰습니다.
- > 이전에는 포즈와 왼손, 오른손 키포인트를 추출 하였는데 포즈 키포인트는
모든 자료에서 중복되는 부분이 1/3을 차지하여 제거 하였고 왼손, 오른손 키포인트
만 추출하여 진행하였습니다. 지금까지는 가장 개선 된 인식률을 보이고 있습니다.


질문 1 : 단어를 추가로 학습을 할려고 했을 때 저희가 이전에
학습시켰던 모델에 덧붙여서 학습을 시킬 수 있을까요?

질문 2 : 같은 데이터를 같은 모델에 
학습시켰는데 accuracy의 값이 크게 차이가 나는 경우가 빈번한데 
이유가 있나요?

질문 3 : 기존에는 단어를 끊어서 하나씩 인식하여 단어들을 모델에 넣어서 
문장을 출력하도록 진행하였습니다.
이후에는 실제 농인이 수어를 하는것처럼 동작을 이어서 인식을 진행할려고
합니다. 그러나 기존의 모델에 잘 적용될지가 의문점입니다. 
다른 방법을 잘 찾지 못하여 이에대한 조언을 구하고 싶습니다.

https://www.youtube.com/watch?v=VjainPzPo2k






